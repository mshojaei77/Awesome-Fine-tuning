Below are three separate tables—one each for Llama, Gemma, and Qwen/DeepSeek models. Within each table the rows are ordered (from top to bottom) according to our judgment of model version and notebook value (i.e. more advanced or feature‐rich approaches are listed first).

---

### Llama Models

| Model                                                                                           | Method                       | Library         | Notebook URL                                                                                                                                                                         | Description                                                                                                                     |
|-------------------------------------------------------------------------------------------------|------------------------------|-----------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| Llama_3_2_1B+3B_Conversational_+_2x_faster_finetuning.ipynb                                      | General, Faster Fine-Tuning  | –               | [Llama_3_2_1B+3B_Conversational_+_2x_faster_finetuning.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/Llama_3_2_1B+3B_Conversational_+_2x_faster_finetuning.ipynb) | Conversational fine-tuning for Llama 3 (2.1B & 3B) models using faster techniques.                                               |
| Fine_tune_Llama_3_with_ORPO.ipynb                                                                 | ORPO                         | –               | [Fine_tune_Llama_3_with_ORPO.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/Fine_tune_Llama_3_with_ORPO.ipynb)                                             | Fine-tuning Llama 3 using Odds Ratio Policy Optimization.                                                                       |
| Finetune_Llama3_with_LLaMA_Factory.ipynb                                                          | LLaMA-Factory                | LLaMA-Factory   | [Finetune_Llama3_with_LLaMA_Factory.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/Finetune_Llama3_with_LLaMA_Factory.ipynb)                                | Fine-tuning Llama 3 using the LLaMA-Factory library.                                                                            |

---

### Gemma Models

The Gemma family is presented here in three groups: **Gemma 2** (most recent/advanced), **Gemma 1** (intermediate), and the original **Gemma**. Within each subgroup, notebooks employing advanced methods (e.g. QLoRA, Function Calling, full fine-tuning) are listed first.

| Model                                                                  | Method                 | Library       | Notebook URL                                                                                                                                                   | Description                                                                                                                       |
|------------------------------------------------------------------------|------------------------|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| **_Gemma 2_**                                                          |                        |               |                                                                                      | **Gemma 2 Models**                                                                                                                |
| [Gemma_2]Finetune_with_Axolotl.ipynb                                     | Axolotl                | Axolotl       | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_Axolotl.ipynb)                                                  | Fine-tuning Gemma 2 using the Axolotl library.                                                                                     |
| [Gemma_2]Finetune_with_CALM.ipynb                                        | CALM                   | CALM          | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_CALM.ipynb)                                                     | Fine-tuning Gemma 2 using the CALM library.                                                                                        |
| [Gemma_2]Finetune_with_Function_Calling.ipynb                            | Function Calling       | PyTorch/XLA   | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_Function_Calling.ipynb)                                           | Fine-tuning Gemma 2 for function calling with PyTorch/XLA.                                                                       |
| [Gemma_2]Finetune_with_JORA.ipynb                                        | JORA                   | JORA          | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_JORA.ipynb)                                                     | Fine-tuning Gemma 2 using the JORA library.                                                                                        |
| [Gemma_2]Finetune_with_LitGPT.ipynb                                      | LitGPT                 | LitGPT        | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_LitGPT.ipynb)                                                   | Fine-tuning Gemma 2 using the LitGPT library.                                                                                      |
| [Gemma_2]Finetune_with_Torch_XLA.ipynb                                   | General                | PyTorch/XLA   | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_Torch_XLA.ipynb)                                                | Fine-tuning Gemma 2 using PyTorch/XLA.                                                                                             |
| [Gemma_2]Finetune_with_Unsloth.ipynb                                     | Unsloth                | Unsloth       | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DFinetune_with_Unsloth.ipynb)                                                  | Fine-tuning Gemma 2 using the Unsloth library.                                                                                     |
| [Gemma_2]Translator_of_Old_Korean_Literature.ipynb                       | Translation            | Keras         | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_2%5DTranslator_of_Old_Korean_Literature.ipynb)                                       | Using Gemma 2 to translate old Korean literature with Keras.                                                                     |
| finetune_paligemma_on_multiple_detection_dataset.ipynb                 | General                | –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/finetune_paligemma_on_multiple_detection_dataset.ipynb)                                      | Fine-tuning PaliGemma (Gemma 2 variant) on multiple object detection datasets.                                                   |
| gemma-2_2b_qlora.ipynb                                                   | QLoRA                  | –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/gemma-2_2b_qlora.ipynb)                                                                     | Fine-tuning Gemma 2 2B using QLoRA.                                                                                                  |
| gemma-2_9b_qlora.ipynb                                                   | QLoRA                  | –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/gemma_2_9b_qlora.ipynb)                                                                     | Fine-tuning Gemma 2 9B using QLoRA.                                                                                                  |
| gemma_2_9b_qlora_unsloth.ipynb                                           | QLoRA                  | Unsloth       | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/gemma_2_9b_qlora_unsloth.ipynb)                                                             | Fine-tuning Gemma 2 9B using QLoRA with Unsloth optimization.                                                                      |
| gemma2(2b)_fc_ft.ipynb                                                   | Full Fine-Tuning       | –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/gemma2(2b)_fc_ft.ipynb)                                                                     | Full fine-tuning of the Gemma 2 2B model.                                                                                          |
| gemma_2b_qlora.ipynb                                                     | QLoRA                  | –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/gemma_2b_qlora.ipynb)                                                                       | Fine-tuning Gemma 2B using QLoRA.                                                                                                    |
| **_Gemma 1_**                                                          |                        |               |                                                                                      | **Gemma 1 Models**                                                                                                                |
| [Gemma_1]Finetune_with_LLaMA_Factory.ipynb                               | LLaMA-Factory          | LLaMA-Factory | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_1%5DFinetune_with_LLaMA_Factory.ipynb)                                              | Fine-tuning Gemma (version 1) using LLaMA-Factory.                                                                                 |
| [Gemma_1]Finetune_with_XTuner.ipynb                                      | XTuner                 | XTuner        | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_1%5DFinetune_with_XTuner.ipynb)                                                     | Fine-tuning Gemma (version 1) using the XTuner library.                                                                            |
| [Gemma_1]Finetune_distributed.ipynb                                      | Distributed Fine-Tuning| –             | [Link](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/%5BGemma_1%5DFinetune_distributed.ipynb)                                                     | Distributed fine-tuning for chat applications with Gemma (version 1).                                                              |
| **_Original Gemma_**                                                   |                        |               |                                                                                      | **Original Gemma Model**                                                                                                          |
| Gemma_Fine_tuning.ipynb                                                  | General                | –             | [Gemma_Fine_tuning.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/Gemma_Fine_tuning.ipynb)                                                   | General fine-tuning notebook for Gemma models.                                                                                    |

---

### Qwen / DeepSeek Models

| Model                                        | Method         | Library | Notebook URL                                                                                                                                           | Description                                                                                                                       |
|----------------------------------------------|----------------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| DeepSeek-R1-Distill-Qwen-1.5B                 | SFT            | TRL     | [Deepseek_Llava_VLM_trl.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/Deepseek_Llava_VLM_trl.ipynb)                               | Fine-tuning DeepSeek-Llava VLM using Transformer Reinforcement Learning.                                                         |
| Qwen-0.5B                                    | GRPO Training  | TRL     | [qwen_grpo_training.ipynb](https://github.com/mshojaei77/Awesome-Fine-tuning/blob/main/qwen_grpo_training.ipynb)                                       | GRPO training on the Taylor Swift QA dataset.                                                                                   |

---

Feel free to adjust the ordering or add further details as your repository evolves.
